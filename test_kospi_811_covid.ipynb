{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.mstats import winsorize\n",
    "from statsmodels.stats.sandwich_covariance import cov_hac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#   1. Functions\n",
    "# =============================================================================\n",
    "\n",
    "# Data cleaning: handling months with insufficient data\n",
    "def handle_outlier_months(daily_rtn_df):\n",
    "    for stock in daily_rtn_df.columns:\n",
    "        monthly_count = daily_rtn_df[stock].resample('ME').count()\n",
    "        months_to_nan = monthly_count[monthly_count < 7].dropna().index\n",
    "        daily_rtn_df.loc[daily_rtn_df.index.to_period('M').isin(months_to_nan.to_period('M')), stock] = np.nan\n",
    "    return daily_rtn_df\n",
    "\n",
    "# Semibeta calculation\n",
    "def semibeta(r_signed, m_signed, m_total):\n",
    "    num_df = r_signed * m_signed.values\n",
    "    denom_df = m_total ** 2\n",
    "    sum_num_df = num_df.resample('ME').sum(min_count=1)\n",
    "    sum_denom_df = denom_df.resample('ME').sum(min_count=1)\n",
    "    semibeta_df = sum_num_df / sum_denom_df.values\n",
    "    return semibeta_df\n",
    "\n",
    "def semibeta_mix(r_signed, m_signed, m_total):\n",
    "    num_df = r_signed * m_signed.values\n",
    "    denom_df = m_total ** 2\n",
    "    sum_num_df = num_df.resample('ME').sum(min_count=1)\n",
    "    sum_denom_df = denom_df.resample('ME').sum(min_count=1)\n",
    "    semibeta_df = -sum_num_df / sum_denom_df.values  # sign change\n",
    "    return semibeta_df\n",
    "\n",
    "# Function to winsorize a single column\n",
    "def winsorize_col(series, lower_percentile, upper_percentile):\n",
    "    return pd.Series(winsorize(series, limits=(lower_percentile, upper_percentile)), index=series.index)\n",
    "\n",
    "# Semibeta summary statistics\n",
    "def semibeta_sumstat(semibeta_df):\n",
    "    cross_mean = semibeta_df.mean(axis=1)\n",
    "    cross_std = semibeta_df.std(axis=1, ddof=1)\n",
    "    cross_median = semibeta_df.median(axis=1)\n",
    "    \n",
    "    ts_mean = cross_mean.mean()\n",
    "    ts_std = cross_std.mean()\n",
    "    ts_median = cross_median.mean()\n",
    "    \n",
    "    return ts_mean, ts_std, ts_median\n",
    "\n",
    "# Time-series mean of cross-sectional correlation\n",
    "def average_cross_sec_corr(matrix1, matrix2):\n",
    "    correlations = []\n",
    "    for i in range(len(matrix1)):\n",
    "        corr = matrix1.iloc[i].corr(matrix2.iloc[i], 'pearson')\n",
    "        correlations.append(corr)\n",
    "    return np.mean(correlations)\n",
    "\n",
    "def newey_west_se(lambdas, nlags):\n",
    "    results = sm.OLS(lambdas, np.ones(len(lambdas))).fit()\n",
    "    nw_cov = cov_hac(results, nlags=nlags)\n",
    "    nw_se = np.sqrt(np.diag(nw_cov))\n",
    "    return nw_se\n",
    "\n",
    "def newey_west_tstat(lambdas, mean_lambdas, nlags):\n",
    "    nw_se = newey_west_se(lambdas, nlags)\n",
    "    nw_tstat = mean_lambdas / nw_se\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(nw_tstat)))\n",
    "    return nw_tstat, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#   X. Data loading\n",
    "# =============================================================================\n",
    "\n",
    "file_path = './data/kor/final/'\n",
    "r = pd.read_csv(f'{file_path}KOSPI_r_daily_811_covid.csv')\n",
    "# r_monthly = pd.read_csv(f'{file_path}KOSPI_r_monthly_811_paper.xlsx')\n",
    "m = pd.read_csv(f'{file_path}KOSPI_m_daily_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/kjbh4_8964599ypdwfdp5b640000gn/T/ipykernel_11528/2048044915.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  r['Symbol'] = pd.to_datetime(r['Symbol'])\n",
      "/var/folders/bp/kjbh4_8964599ypdwfdp5b640000gn/T/ipykernel_11528/2048044915.py:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  m['Symbol'] = pd.to_datetime(m['Symbol'])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#   X. Data cleaning\n",
    "# =============================================================================\n",
    "\n",
    "# Data cleaning (r)\n",
    "col_name_r = r.iloc[7].tolist()\n",
    "r = r.drop(r.index[0:13])\n",
    "r.columns = col_name_r\n",
    "r['Symbol'] = pd.to_datetime(r['Symbol'])\n",
    "r.set_index('Symbol', inplace=True)\n",
    "r.index.name = None\n",
    "r = r.astype('float64')\n",
    "r = r / 100\n",
    "\n",
    "# # Data cleaning (r_monthly)\n",
    "# col_name_r_monthly = r_monthly.iloc[7].dropna().tolist()\n",
    "# r_monthly = r_monthly.drop(r_monthly.index[0:13])\n",
    "# r_monthly.columns = col_name_r_monthly\n",
    "# r_monthly['Symbol'] = pd.to_datetime(r_monthly['Symbol'])\n",
    "# r_monthly.set_index('Symbol', inplace=True)\n",
    "# r_monthly.index.name = None\n",
    "# r_monthly = r_monthly.astype('float64')\n",
    "# r_monthly = r_monthly / 100\n",
    "\n",
    "# Data cleaning (m)\n",
    "col_name_m = m.iloc[7].dropna().tolist()\n",
    "m = m.drop(m.index[0:13])\n",
    "m = m.iloc[:, :-1]\n",
    "m.columns = col_name_m\n",
    "m['Symbol'] = pd.to_datetime(m['Symbol'])\n",
    "m.set_index('Symbol', inplace=True)\n",
    "m.index.name = None\n",
    "m = m.astype('float64')\n",
    "m = m / 100\n",
    "\n",
    "# Extract positive and negative returns\n",
    "r_pos = r.mask(r < 0, 0)\n",
    "r_neg = r.mask(r > 0, 0)\n",
    "m_pos = m.mask(m < 0, 0)\n",
    "m_neg = m.mask(m > 0, 0)\n",
    "\n",
    "# Handle outlier months with less than 10 data points\n",
    "r = handle_outlier_months(r)\n",
    "m = handle_outlier_months(m)\n",
    "r_pos = handle_outlier_months(r_pos)\n",
    "r_neg = handle_outlier_months(r_neg)\n",
    "m_pos = handle_outlier_months(m_pos)\n",
    "m_neg = handle_outlier_months(m_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             B       B_N       B_P      B_M+      B_M-\n",
      "Mean  0.967195  0.686311  0.538842  0.102022  0.155937\n",
      "Std   0.642442  0.327676  0.350387  0.145789  0.273188\n",
      "Med   0.964514  0.670893  0.478587  0.058249  0.075422\n",
      "\n",
      "             B       B_N       B_P      B_M+ B_M-\n",
      "B          1.0       NaN       NaN       NaN  NaN\n",
      "B_N   0.627099       1.0       NaN       NaN  NaN\n",
      "B_P   0.565486  0.033365       1.0       NaN  NaN\n",
      "B_M+ -0.290446 -0.065968   0.24383       1.0  NaN\n",
      "B_M- -0.439389  0.032286  0.090742  0.380278  1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#   2. Semibeta calculation\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate monthly semibetas\n",
    "beta_CAPM = semibeta(r, m, m)\n",
    "beta_N = semibeta(r_neg, m_neg, m)\n",
    "beta_P = semibeta(r_pos, m_pos, m)\n",
    "beta_M_pos = semibeta_mix(r_neg, m_pos, m)\n",
    "beta_M_neg = semibeta_mix(r_pos, m_neg, m)\n",
    "\n",
    "# Winsorize semibetas at 1% and 99% levels\n",
    "lower_percentile = 0.01\n",
    "upper_percentile = 0.01\n",
    "beta_CAPM = beta_CAPM.apply(winsorize_col, lower_percentile=lower_percentile, upper_percentile=upper_percentile)\n",
    "beta_N = beta_N.apply(winsorize_col, lower_percentile=lower_percentile, upper_percentile=upper_percentile)\n",
    "beta_P = beta_P.apply(winsorize_col, lower_percentile=lower_percentile, upper_percentile=upper_percentile)\n",
    "beta_M_pos = beta_M_pos.apply(winsorize_col, lower_percentile=lower_percentile, upper_percentile=upper_percentile)\n",
    "beta_M_neg = beta_M_neg.apply(winsorize_col, lower_percentile=lower_percentile, upper_percentile=upper_percentile)\n",
    "\n",
    "# Semibeta summary statistics\n",
    "sumstat_index = ['Mean', 'Std', 'Med']\n",
    "sumstat_col = ['B', 'B_N', 'B_P', 'B_M+', 'B_M-']\n",
    "sumstat = pd.DataFrame(index=sumstat_index, columns=sumstat_col)\n",
    "sumstat['B'] = semibeta_sumstat(beta_CAPM)\n",
    "sumstat['B_N'] = semibeta_sumstat(beta_N)\n",
    "sumstat['B_P'] = semibeta_sumstat(beta_P)\n",
    "sumstat['B_M+'] = semibeta_sumstat(beta_M_pos)\n",
    "sumstat['B_M-'] = semibeta_sumstat(beta_M_neg)\n",
    "\n",
    "# Correalation between semibetas (simple element-wise)\n",
    "betas = [beta_CAPM, beta_N, beta_P, beta_M_pos, beta_M_neg]\n",
    "corr_matrix_label = ['B', 'B_N', 'B_P', 'B_M+', 'B_M-']\n",
    "corr_matrix = pd.DataFrame(index=corr_matrix_label, columns=corr_matrix_label)\n",
    "\n",
    "for i in range(len(betas)):\n",
    "    for j in range(i, len(betas)):\n",
    "        if i == j:\n",
    "            corr_matrix.iloc[i, j] = 1.0\n",
    "        else:\n",
    "            flat1 = betas[i].values.flatten()\n",
    "            flat2 = betas[j].values.flatten()\n",
    "            combined_df = pd.DataFrame({'flat1': flat1, 'flat2': flat2})\n",
    "            clean_df = combined_df.dropna()\n",
    "            corr = np.corrcoef(clean_df['flat1'], clean_df['flat2'])[0, 1]\n",
    "            # corr_matrix.iloc[i, j] = corr\n",
    "            corr_matrix.iloc[j, i] = corr\n",
    "            \n",
    "# Output summary stats\n",
    "print(sumstat)\n",
    "print()\n",
    "print(corr_matrix)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sig diff between ref results\n",
      "             B       B_N  B_P      B_M+  B_M-\n",
      "Mean -0.257195 -0.146311  NaN  0.107978   NaN\n",
      "Med  -0.294514 -0.220893  NaN       NaN   NaN\n",
      "Std        NaN       NaN  NaN       NaN   NaN\n",
      "Stdv       NaN       NaN  NaN       NaN   NaN\n",
      "\n",
      "             B       B_N       B_P B_M+ B_M-\n",
      "B          NaN       NaN       NaN  NaN  NaN\n",
      "B_N        NaN       NaN       NaN  NaN  NaN\n",
      "B_P        NaN  0.106635       NaN  NaN  NaN\n",
      "B_M+       NaN  0.105968       NaN  NaN  NaN\n",
      "B_M-  0.099389  0.067714  0.099258  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#   X. Comparison with reference paper\n",
    "# =============================================================================\n",
    "\n",
    "# Reference paper sumstat\n",
    "ref_index = ['Mean', 'Stdv', 'Med']\n",
    "ref_data = {\n",
    "    'B': [0.71, 0.71, 0.67],\n",
    "    'B_N': [0.54, 0.41, 0.45],\n",
    "    'B_P': [0.58, 0.46, 0.47],\n",
    "    'B_M+': [0.21, 0.26, 0.13],\n",
    "    'B_M-': [0.20, 0.27, 0.10]\n",
    "}\n",
    "ref_df = pd.DataFrame(index=ref_index, data=ref_data)\n",
    "\n",
    "# Reference paper correlation matrix\n",
    "ref_index2 = ['B', 'B_N', 'B_P', 'B_M+', 'B_M-']\n",
    "ref_data2 = {\n",
    "    'B': [1.00, 0.61, 0.58, -0.34, -0.34],\n",
    "    'B_N': [np.nan, 1.00, 0.14, 0.04, 0.10],\n",
    "    'B_P': [np.nan, np.nan, 1.00, 0.21, 0.19],\n",
    "    'B_M+': [np.nan, np.nan, np.nan, 1.00, 0.38],\n",
    "    'B_M-': [np.nan, np.nan, np.nan, np.nan, 1.00]\n",
    "}\n",
    "ref_matrix = pd.DataFrame(index=ref_index2, data=ref_data2)\n",
    "\n",
    "print('Sig diff between ref results')\n",
    "stat_diff = ref_df - sumstat\n",
    "stat_diff = stat_diff.where(stat_diff.abs() > 0.1, np.nan)\n",
    "print(stat_diff)\n",
    "\n",
    "print()\n",
    "corr_diff = ref_matrix - corr_matrix\n",
    "corr_diff = corr_diff.where(corr_diff.abs() > 0.05, np.nan)\n",
    "print(corr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly stock returns\n",
    "r_monthly = r.resample('ME').apply(lambda x: np.nan if pd.isna(x).all() else (1 + x).prod() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: -1.66 (-1.03) (0.30)\n",
      "CAPM: 0.60 (0.98) (0.33)\n",
      "R^2: 2.7424254733190394\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#   3. Fama-MacBeth type predictive regression: CAPM\n",
    "# =============================================================================\n",
    "\n",
    "# Cross-sectional regression\n",
    "lambda_0, lambda_CAPM, rsquared = [], [], []\n",
    "models = []\n",
    "\n",
    "for i in range(1, len(r_monthly)):\n",
    "    temp_df = pd.DataFrame({'CAPM': beta_CAPM.iloc[i-1], \n",
    "                            'r': r_monthly.iloc[i]})\n",
    "    temp_df = temp_df.dropna()\n",
    "    x = sm.add_constant(temp_df[['CAPM']])\n",
    "    y = temp_df['r']\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    models.append(model)\n",
    "    lambda_0.append(model.params['const'])\n",
    "    lambda_CAPM.append(model.params['CAPM'])\n",
    "    rsquared.append(model.rsquared)\n",
    "\n",
    "# Results\n",
    "lambdas = pd.DataFrame({'lambda_0': lambda_0, 'lambda_CAPM': lambda_CAPM})\n",
    "mean_lambdas = lambdas.mean()\n",
    "\n",
    "# Monthly risk premia estimate (%)\n",
    "lambda_0_coef = mean_lambdas['lambda_0'] * 100\n",
    "lambda_CAPM_coef = mean_lambdas['lambda_CAPM'] * 100\n",
    "\n",
    "# Newwey-West t-statistic\n",
    "nlags = round(0.75 * len(r_monthly)**(1/3))\n",
    "nw_tstat0, p_values0 = newey_west_tstat(lambdas['lambda_0'], mean_lambdas['lambda_0'], nlags)\n",
    "nw_tstat1, p_values1 = newey_west_tstat(lambdas['lambda_CAPM'], mean_lambdas['lambda_CAPM'], nlags)\n",
    "\n",
    "# R-squared\n",
    "rsquared_mean = np.mean(rsquared) * 100\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f'Constant: {lambda_0_coef:.2f} ({nw_tstat0[0]:.2f}) ({p_values0[0]:.2f})')\n",
    "print(f'CAPM: {lambda_CAPM_coef:.2f} ({nw_tstat1[0]:.2f}) ({p_values1[0]:.2f})')\n",
    "print('R^2:', rsquared_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: -0.78 (-0.71) (0.48)\n",
      "N: -0.61 (-0.45) (0.66)\n",
      "P: -0.61 (-0.76) (0.44)\n",
      "M_pos: -1.80 (-0.99) (0.32)\n",
      "M_neg: -2.10 (-1.42) (0.16)\n",
      "R^2: 5.922366547768163\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#   3. Fama-MacBeth type predictive regression: 4 Semibetas\n",
    "# =============================================================================\n",
    "\n",
    "# Cross-sectional regression\n",
    "lambda_0, lambda_N, lambda_P, lambda_M_pos, lambda_M_neg, rsquared = [], [], [], [], [], []\n",
    "for i in range(1, len(r_monthly)):\n",
    "    temp_df = pd.DataFrame({'N': beta_N.iloc[i-1], \n",
    "                            'P': beta_P.iloc[i-1], \n",
    "                            'M_pos': beta_M_pos.iloc[i-1], \n",
    "                            'M_neg': beta_M_neg.iloc[i-1], \n",
    "                            'r': r_monthly.iloc[i]})\n",
    "    temp_df = temp_df.dropna()\n",
    "    x = sm.add_constant(temp_df[['N', 'P', 'M_pos', 'M_neg']])\n",
    "    y = temp_df['r']\n",
    "    model = sm.OLS(y, x).fit()\n",
    "    lambda_0.append(model.params['const'])\n",
    "    lambda_N.append(model.params['N'])\n",
    "    lambda_P.append(model.params['P'])\n",
    "    lambda_M_pos.append(model.params['M_pos'])\n",
    "    lambda_M_neg.append(model.params['M_neg'])\n",
    "    rsquared.append(model.rsquared)\n",
    "\n",
    "# Results\n",
    "lambdas = pd.DataFrame({'lambda_0': lambda_0, 'lambda_N': lambda_N, 'lambda_P': lambda_P, 'lambda_M_pos': lambda_M_pos, 'lambda_M_neg': lambda_M_neg})\n",
    "mean_lambdas = lambdas.mean()\n",
    "\n",
    "# Monthly risk premia estimate (%)\n",
    "lambda_0_coef = mean_lambdas['lambda_0'] * 100\n",
    "lambda_N_coef = mean_lambdas['lambda_N'] * 100\n",
    "lambda_P_coef = mean_lambdas['lambda_P'] * 100\n",
    "lambda_M_pos_coef = mean_lambdas['lambda_M_pos'] * 100\n",
    "lambda_M_neg_coef = mean_lambdas['lambda_M_neg'] * 100\n",
    "\n",
    "# Newwey-West t-statistic\n",
    "nw_lag = round(0.75 * len(r_monthly)**(1/3))\n",
    "nw_tstat0, p_values0 = newey_west_tstat(lambdas['lambda_0'], mean_lambdas['lambda_0'], nlags)\n",
    "nw_tstat_N, p_values_N = newey_west_tstat(lambdas['lambda_N'], mean_lambdas['lambda_N'], nlags)\n",
    "nw_tstat_P, p_values_P = newey_west_tstat(lambdas['lambda_P'], mean_lambdas['lambda_P'], nlags)\n",
    "nw_tstat_M_pos, p_values_M_pos = newey_west_tstat(lambdas['lambda_M_pos'], mean_lambdas['lambda_M_pos'], nlags)\n",
    "nw_tstat_M_neg, p_values_M_neg = newey_west_tstat(lambdas['lambda_M_neg'], mean_lambdas['lambda_M_neg'], nlags)\n",
    "\n",
    "# R-squared\n",
    "rsquared_mean = np.mean(rsquared) * 100\n",
    "\n",
    "# Print results\n",
    "print(f'Constant: {lambda_0_coef:.2f} ({nw_tstat0[0]:.2f}) ({p_values0[0]:.2f})')\n",
    "print(f'N: {lambda_N_coef:.2f} ({nw_tstat_N[0]:.2f}) ({p_values_N[0]:.2f})')\n",
    "print(f'P: {lambda_P_coef:.2f} ({nw_tstat_P[0]:.2f}) ({p_values_P[0]:.2f})')\n",
    "print(f'M_pos: {lambda_M_pos_coef:.2f} ({nw_tstat_M_pos[0]:.2f}) ({p_values_M_pos[0]:.2f})')\n",
    "print(f'M_neg: {lambda_M_neg_coef:.2f} ({nw_tstat_M_neg[0]:.2f}) ({p_values_M_neg[0]:.2f})')\n",
    "print('R^2:', rsquared_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
